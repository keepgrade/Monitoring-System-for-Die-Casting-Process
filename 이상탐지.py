# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì‹œê°í™” íŒ¨í‚¤ì§€ ì„í¬íŠ¸
import pandas as pd                 # ë°ì´í„°í”„ë ˆì„ êµ¬ì¡° ì²˜ë¦¬
import numpy as np                 # ìˆ˜ì¹˜ ê³„ì‚° ë° ë°°ì—´ ì²˜ë¦¬
import janitor                     # ë°ì´í„° ì „ì²˜ë¦¬ ì§€ì› (clean_names ë“±)
import matplotlib.pyplot as plt    # ì‹œê°í™” ë„êµ¬
import seaborn as sns              # ê³ ê¸‰ ì‹œê°í™” ë„êµ¬
import time                        # ì‹œê°„ ì¸¡ì •ìš©
from sklearn.preprocessing import StandardScaler  # ë°ì´í„° ì •ê·œí™” ë„êµ¬

# í•™ìŠµ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
train = pd.read_csv("train.csv")     # í›ˆë ¨ìš© CSV íŒŒì¼ ë¡œë“œ
train.info()                         # ë°ì´í„° êµ¬ì¡°(ê²°ì¸¡ì¹˜, íƒ€ì… ë“±) í™•ì¸

# ê²€ì¦ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
valid = pd.read_csv("val.csv")       # ê²€ì¦ìš© CSV íŒŒì¼ ë¡œë“œ
valid.info()                         # ê²€ì¦ìš© ë°ì´í„° êµ¬ì¡° í™•ì¸ (class ì—´ì´ ìˆìŒ)

# ë³€ìˆ˜ ì´ë¦„ ì •ë¦¬ (ì†Œë¬¸ì + ë°‘ì¤„ í˜•ì‹ìœ¼ë¡œ ìë™ ì •ë¦¬)
train = train.clean_names()          # ex: "Credit Amount" â†’ "credit_amount"
valid = valid.clean_names()

# ë¶ˆí•„ìš”í•œ 'id' ì—´ ì œê±°
train = train.drop(['id'], axis=1)   # í•™ìŠµ ë°ì´í„°ì˜ id ì œê±° (ì˜ˆì¸¡ì— í•„ìš” ì—†ìŒ)
valid_x = valid.drop(['id', 'class'], axis=1)  # ê²€ì¦ìš© featureë§Œ ë‚¨ê¹€
valid_y = valid['class']            # ì •ë‹µ(label)ë§Œ ë”°ë¡œ ì¶”ì¶œ

# ============================
# LOF(Local Outlier Factor) ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
# ============================

from sklearn.neighbors import LocalOutlierFactor

# ì „ì²´ í•™ìŠµ ë°ì´í„° ìˆ˜(n)ì— ëŒ€í•´ log(n)ë¥¼ ì·¨í•œ ê°’ì„ kê°’(n_neighbors)ë¡œ ì„¤ì •
# ì´ëŠ” ë°€ë„ ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ì—ì„œ ì¼ë°˜ì ì¸ ê²½í—˜ì  ê¸°ì¤€ì„
minpts = np.round(np.log(train.shape[0])).astype(int)  # ì˜ˆ: 10,000ê°œë©´ ì•½ 9~10

# LOF ëª¨ë¸ ê°ì²´ ìƒì„±
clf = LocalOutlierFactor(
    n_neighbors=minpts,           # ğŸ”¹ ì´ìƒ íƒì§€ ì‹œ ê³ ë ¤í•  ì´ì›ƒì˜ ìˆ˜ (k)
    contamination=0.001,          # ğŸ”¹ ì „ì²´ ë°ì´í„° ì¤‘ ì´ìƒì¹˜ ë¹„ìœ¨ ì„¤ì • (0.1%ë¡œ ê°€ì •)
    novelty=True                  # ğŸ”¹ í›ˆë ¨ ë°ì´í„° ì™¸ ìƒˆë¡œìš´ ë°ì´í„°(valid)ì— ëŒ€í•´ predict í—ˆìš©
)
clf.fit(train)                    # í•™ìŠµìš© ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ ì§„í–‰

# (ì°¸ê³ ) ìœ„ì™€ ê°™ì€ íŒŒë¼ë¯¸í„° ì„¤ì •ì˜ ì˜ˆì‹œ
# lof = LocalOutlierFactor(
#     n_neighbors=12,
#     contamination=0.001,
#     novelty=True
# )

# ============================
# ëª¨ë¸ ì˜ˆì¸¡ ë° í‰ê°€
# ============================

from sklearn.metrics import confusion_matrix, classification_report
from sklearn import set_config  # (ì‚¬ìš©í•˜ì§€ ì•Šì•˜ì§€ë§Œ scikit-learn ì„¤ì •ìš©)

# ê²€ì¦ ë°ì´í„°ì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰ (1:ì •ìƒ, -1:ì´ìƒì¹˜)
pred_val = clf.predict(valid_x)

# sklearn LOFëŠ” 1(ì •ìƒ), -1(ì´ìƒì¹˜) í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•¨
# ì´ì™€ ë§ì¶”ê¸° ìœ„í•´ ê²€ì¦ìš© yê°’ì„ ë™ì¼í•˜ê²Œ ì¬ë§¤í•‘
valid_y.replace(1, -1, inplace=True)  # ì‹¤ì œ ì‚¬ê¸°ê±´(class==1)ì„ -1(ì´ìƒì¹˜)ë¡œ ë³€ê²½
valid_y.replace(0, 1, inplace=True)   # ì •ìƒ ê±°ë˜(class==0)ë¥¼ 1ë¡œ ë³€ê²½

# ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë¬¶ê¸°
result = pd.DataFrame({'real': valid_y, 'pred': pred_val})

# í˜¼ë™í–‰ë ¬(Confusion Matrix) ê³„ì‚°
# ì˜ˆ: [[TN, FP], [FN, TP]] êµ¬ì¡°
confusion = confusion_matrix(result.real, result.pred)
print(confusion)

# ì •ë°€ë„(Precision), ì¬í˜„ìœ¨(Recall), F1 Score, Accuracy ë“± í‰ê°€ ì§€í‘œ ì¶œë ¥
print(classification_report(result.real, result.pred))

# ===========================
# Isolation Forest
# ===========================
import pandas as pd
import numpy as np
import janitor  # clean_names í•¨ìˆ˜ ë“± í™œìš©
from sklearn.ensemble import IsolationForest
from sklearn.metrics import confusion_matrix, classification_report

# ===========================
# ğŸ“ 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
# ===========================

# í•™ìŠµ ë° ê²€ì¦ìš© ë°ì´í„° ë¡œë”©
train = pd.read_csv("train.csv")
valid = pd.read_csv("val.csv")

# ë³€ìˆ˜ ì´ë¦„ì„ ê¹”ë”í•œ ì†Œë¬¸ì + ë°‘ì¤„ë¡œ ë³€í™˜
train = train.clean_names()
valid = valid.clean_names()

# idëŠ” ì˜ˆì¸¡ì— ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì œê±°
train = train.drop(['id'], axis=1)
valid_x = valid.drop(['id', 'class'], axis=1)
valid_y = valid['class']  # ì •ë‹µ ë¼ë²¨

# ===========================
# ğŸŒ² 2. Isolation Forest ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
# ===========================

clf = IsolationForest(
    contamination=0.001,  # ğŸ”¹ ì „ì²´ ìƒ˜í”Œ ì¤‘ ì´ìƒì¹˜ ë¹„ìœ¨ ì¶”ì • (0.1%)
    random_state=0        # ğŸ”¹ ê²°ê³¼ ì¬í˜„ì„ ìœ„í•œ ëœë¤ ì‹œë“œ ê³ ì •
)
clf.fit(train)            # ëª¨ë¸ í›ˆë ¨

# ===========================
# ğŸ” 3. ì˜ˆì¸¡ ë° ê²°ê³¼ ë¶„ì„
# ===========================

# (1: ì •ìƒ, -1: ì´ìƒì¹˜)ì˜ í˜•íƒœë¡œ ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜ë¨
pred_val = clf.predict(valid_x)

# ğŸ’¡ ì •ë‹µ ë¼ë²¨ë„ ë™ì¼í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
valid_y.replace(1, -1, inplace=True)  # ì‹¤ì œ ì‚¬ê¸° â†’ ì´ìƒì¹˜(-1)
valid_y.replace(0, 1, inplace=True)   # ì‹¤ì œ ì •ìƒ â†’ ì •ìƒ(1)

# ê²°ê³¼ ë°ì´í„°í”„ë ˆì„ ìƒì„±
result = pd.DataFrame({'real': valid_y, 'pred': pred_val})

# ğŸ”¢ í˜¼ë™ í–‰ë ¬ í™•ì¸
print(confusion_matrix(result.real, result.pred))

# ğŸ“ ì •ë°€ë„, ì¬í˜„ìœ¨, F1 ì ìˆ˜ ë“± ìƒì„¸ ì§€í‘œ ì¶œë ¥
print(classification_report(result.real, result.pred))




import pandas as pd
import numpy as np
import janitor
import matplotlib.pyplot as plt
from sklearn.ensemble import IsolationForest

# ===========================
# ğŸ“ 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
# ===========================

train = pd.read_csv("train.csv")
valid = pd.read_csv("val.csv")

train = train.clean_names()
valid = valid.clean_names()

train = train.drop(['id'], axis=1)
valid_x = valid.drop(['id', 'class'], axis=1)
valid_y = valid['class'].copy()

# ===========================
# ğŸŒ² 2. Isolation Forest ëª¨ë¸ í•™ìŠµ
# ===========================

# contamination ì§€ì •í•˜ì§€ ì•ŠìŒ
clf = IsolationForest(random_state=0)
clf.fit(train)

# ===========================
# ğŸ§® 3. Anomaly Score ê³„ì‚°
# ===========================

# decision_function: ì´ìƒì¹˜ì¼ìˆ˜ë¡ score â†“ (ì •ìƒì€ score â†‘)
scores = -clf.decision_function(valid_x)  # ë¶€í˜¸ ë°˜ì „í•˜ì—¬ "í´ìˆ˜ë¡ ì´ìƒì¹˜"ë¡œ ì„¤ì •

# íˆìŠ¤í† ê·¸ë¨ìœ¼ë¡œ ì´ìƒì¹˜ ë¶„í¬ ì‹œê°í™”
plt.figure(figsize=(8, 4))
plt.hist(scores, bins=50, color='skyblue')
plt.title("Anomaly Score Distribution")
plt.xlabel("Score (Higher = More Anomalous)")
plt.ylabel("Frequency")
plt.axvline(np.percentile(scores, 99), color='red', linestyle='--', label='Top 1% Threshold')
plt.legend()
plt.show()

# ===========================
# âœ‚ï¸ 4. Threshold ê¸°ë°˜ ì´ìƒì¹˜ íŒë‹¨
# ===========================

# ì´ìƒì¹˜ ê¸°ì¤€ threshold ì„¤ì • (ì˜ˆ: ìƒìœ„ 1%)
threshold = np.percentile(scores, 99)  # ìƒìœ„ 1%ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼
pred_val = np.where(scores >= threshold, -1, 1)  # scoreê°€ í¬ë©´ ì´ìƒì¹˜ (-1), ì•„ë‹ˆë©´ ì •ìƒ (1)

# ===========================
# ğŸ“Š 5. ì„±ëŠ¥ í‰ê°€
# ===========================

from sklearn.metrics import confusion_matrix, classification_report

# ë¼ë²¨ í¬ë§· ë§ì¶¤ (1: ì •ìƒ, -1: ì‚¬ê¸°)
valid_y.replace({1: -1, 0: 1}, inplace=True)

result = pd.DataFrame({'real': valid_y, 'pred': pred_val})

print("ğŸ“Œ Confusion Matrix")
print(confusion_matrix(result.real, result.pred))

print("\nğŸ“Œ Classification Report")
print(classification_report(result.real, result.pred))









class RealTimeStreamer:
    def __init__(self):
        self.test_df = streaming_df.copy()
        self.pointer = 0
        self.current_data = pd.DataFrame(columns=selected_cols)

        # âœ… í†µí•©ëœ ëˆ„ì  ë°ì´í„°í”„ë ˆì„ (ì´ˆê¸°ê°’ = static_dfì˜ ê³µí†µ ì»¬ëŸ¼ë§Œ)
        self.total_df = static_df[self._common_columns()].copy()

    def get_next_batch(self, n=1):
        if self.pointer >= len(self.test_df):
            return None

        end = min(self.pointer + n, len(self.test_df))
        batch = self.test_df.iloc[self.pointer:end]

        # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ ë° ì „ì²˜ë¦¬
        batch = self._preprocess(batch)

        # ëˆ„ì  ì €ì¥
        self.current_data = pd.concat([self.current_data, batch], ignore_index=True)
        self.total_df = pd.concat([self.total_df, batch], ignore_index=True)

        self.pointer = end
        return batch

    def get_current_data(self):
        """í˜„ì¬ê¹Œì§€ ìŠ¤íŠ¸ë¦¬ë°ëœ ë°ì´í„° (ì„ íƒëœ ì»¬ëŸ¼ ê¸°ì¤€)"""
        return self.current_data

    def get_total_data(self):
        """static_df + streaming_df ëˆ„ì ëœ ì „ì²´ ë°ì´í„°"""
        return self.total_df

    def reset_stream(self):
        """ìŠ¤íŠ¸ë¦¬ë° ìƒíƒœ ì´ˆê¸°í™”"""
        self.pointer = 0
        self.current_data = pd.DataFrame(columns=selected_cols)
        self.total_df = static_df[self._common_columns()].copy()

    def get_stream_info(self):
        """ì§„í–‰ë¥  ì •ë³´ ë°˜í™˜"""
        progress = 100 * self.pointer / len(self.test_df)
        return {
            "progress": progress,
            "total": len(self.test_df),
            "current": self.pointer
        }

    def _preprocess(self, df):
        """í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì¶”ì¶œ (í–¥í›„ ì „ì²˜ë¦¬ í™•ì¥ ê°€ëŠ¥)"""
        return df[self._common_columns()].copy()

    def _common_columns(self):
        """static_dfì™€ streaming_df ê°„ ê³µí†µ ì»¬ëŸ¼ ë°˜í™˜"""
        return sorted(set(static_df.columns).intersection(set(streaming_df.columns)))
