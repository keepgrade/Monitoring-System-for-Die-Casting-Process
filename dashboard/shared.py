# ================================
# shared.py
# âœ… ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜ ê³µì • ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œìš© ê³µí†µ ëª¨ë“ˆ
# - ë°ì´í„° ë¡œë”©
# - ì„¼ì„œ ì´ë¦„ ì •ì˜
# - ì‹¤ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜ í´ë˜ìŠ¤ ì •ì˜
# ================================

import pandas as pd
from pathlib import Path
import joblib

# ================================
# ğŸ“ ë°ì´í„° ë¡œë”©
# ================================
app_dir = Path(__file__).parent

# âœ… ì •ì  ë°ì´í„° (ëˆ„ì  ë°ì´í„° ë¶„ì„ìš©)
try:
    static_df = pd.read_csv(app_dir / "./data/df_final.csv", encoding="utf-8")
except UnicodeDecodeError:
    static_df = pd.read_csv(app_dir / "./data/df_final.csv",  encoding="ISO-8859-1")

# âœ… ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„° (ì‹¤ì‹œê°„ ì‹œê°í™”ìš©)
try:
    streaming_df = pd.read_csv(app_dir / "./data/streaming_df.csv",  encoding="utf-8")
except UnicodeDecodeError:
    streaming_df = pd.read_csv(app_dir / "./data/streaming_df.csv",  encoding="cp949")


# âœ… ì´ìƒì¹˜ íŒë‹¨ ê¸°ì¤€ ë¡œë“œ (ë²”ìœ„ ê¸°ë°˜)
try:
    spec_df_all = pd.read_csv(app_dir / "./data/iqr_bounds_by_mold_code.csv", encoding="utf-8")
except UnicodeDecodeError:
    spec_df_all = pd.read_csv(app_dir / "./data/iqr_bounds_by_mold_code.csv", encoding="cp949")

# âœ… ì»¬ëŸ¼ ì •ë¦¬
spec_df_all.columns = ["mold_code", "variable", "lower", "upper"]


# âœ… ì„¼ì„œ ë°ì´í„°ì˜ ì‚¬ëŒì´ ì½ê¸° ì‰¬ìš´ í•œê¸€ ì´ë¦„ê³¼ ë‹¨ìœ„ ì •ì˜
# UI ì¹´ë“œë‚˜ ê·¸ë˜í”„ ë¼ë²¨ë§ ì‹œ í™œìš©
sensor_labels = {
    "molten_temp": ("ìš©íƒ•ì˜¨ë„", "Â°C"),
    "cast_pressure": ("ì£¼ì¡°ì••ë ¥", "bar"),
    "high_section_speed": ("ê³ ì†êµ¬ê°„ì†ë„", "mm/s")
    # í•„ìš” ì‹œ ë” ì¶”ê°€
}
# ì‚¬ìš©í•  ì„¼ì„œ ì»¬ëŸ¼ ì„ íƒ
selected_cols = [
    'mold_code',
    'registration_time',
    'molten_temp',           # ìš©íƒ• ì˜¨ë„
    'cast_pressure',         # ì£¼ì¡° ì••ë ¥
    'high_section_speed',    # ê³ ì† êµ¬ê°„ ì†ë„
    'low_section_speed',     # ì €ì† êµ¬ê°„ ì†ë„
    'biscuit_thickness',      # ë¹„ìŠ¤í‚· ë‘ê»˜
    'passorfail',
    'is_anomaly',
    'anomaly_level',
    'top1',
    'top2',
    'top3',
    'physical_strength',
    'heating_furnace',
    'tryshot_signal',
    'lower_mold_temp2',
    'facility_operation_cycleTime',
    'upper_mold_temp2',
    'production_cycletime',
    'anomaly_score',
    'count',
    'Coolant_temperature',
    'sleeve_temperature',
    'molten_volume',
    'upper_mold_temp1',
    'EMS_operation_time',
    'lower_mold_temp1', 
    'working'

]
df_selected = streaming_df[selected_cols].reset_index(drop=True)

# ================================
# ğŸ”§ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë° í´ë˜ìŠ¤ ì •ì˜
# ================================
class RealTimeStreamer:
    def __init__(self):
        self.full_data = df_selected.copy()
        self.current_index = 0

    def get_next_batch(self, batch_size=1):
        if self.current_index >= len(self.full_data):
            return None
        end_index = min(self.current_index + batch_size, len(self.full_data))
        batch = self.full_data.iloc[self.current_index:end_index].copy()
        self.current_index = end_index
        return batch

    def get_current_data(self):
        if self.current_index == 0:
            return pd.DataFrame()
        return self.full_data.iloc[:self.current_index].copy()

    def reset_stream(self):
        self.current_index = 0

    def get_stream_info(self):
        return {
            'total_rows': len(self.full_data),
            'current_index': self.current_index,
            'progress': (self.current_index / len(self.full_data)) * 100 if len(self.full_data) > 0 else 0
        }


class StreamAccumulator:
    def __init__(self, base_df: pd.DataFrame):
        # ëˆ„ì ì— ì‚¬ìš©í•  ê¸°ì¤€ ì»¬ëŸ¼ (ìµœì´ˆ static_df ê¸°ë°˜)
        self.columns = list(base_df.columns)
        self.total_df = base_df.copy()

    def accumulate(self, new_data: pd.DataFrame):
        if not new_data.empty:
            try:
                available_cols = [col for col in self.columns if col in new_data.columns]
                new_data = new_data[available_cols].copy()
                self.total_df = pd.concat([self.total_df, new_data], ignore_index=True)
            except Exception as e:
                print(f"[â›” accumulate ì¤‘ ì˜¤ë¥˜] {e}")

    def get_data(self):
        return self.total_df.copy()

    def reset(self):
        # ëˆ„ì  ë°ì´í„°í”„ë ˆì„ì„ ì´ˆê¸° ìƒíƒœ(static_df ê¸°ë°˜)ë¡œ ë¦¬ì…‹
        self.total_df = static_df[self._common_columns()].copy()

    def _common_columns(self):
        # static_dfì™€ streaming_df ê°„ì˜ ê³µí†µ ì»¬ëŸ¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        return sorted(set(static_df.columns).intersection(set(streaming_df.columns)))

import requests

def get_weather(lat=32.7767, lon=-96.7970):
    try:
        url = "https://api.open-meteo.com/v1/forecast"
        params = {
            "latitude": lat,
            "longitude": lon,
            "current_weather": True,
            "timezone": "America/Chicago"
        }
        response = requests.get(url, params=params, timeout=5)

        if response.status_code != 200:
            return f"ğŸ”Œ ì˜¤ë¥˜ ì½”ë“œ [{response.status_code}] Â· ë‚ ì”¨ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        data = response.json()
        weather = data["current_weather"]
        temp = round(weather["temperature"])
        windspeed = weather["windspeed"]
        time = weather["time"]

        # Open-MeteoëŠ” ë‚ ì”¨ ì„¤ëª… ëŒ€ì‹  weathercode ì‚¬ìš©
        # â†’ ì•„ë˜ëŠ” ê°„ë‹¨í•œ ë‚ ì”¨ ì½”ë“œ â†’ ì„¤ëª… ë° ì´ëª¨ì§€ ë§¤í•‘
        code_map = {
            0: ("â˜€ï¸", "ë§‘ìŒ"),
            1: ("ğŸŒ¤ï¸", "ë¶€ë¶„ ë§‘ìŒ"),
            2: ("â›…", "êµ¬ë¦„ ë§ìŒ"),
            3: ("â˜ï¸", "íë¦¼"),
            45: ("ğŸŒ«ï¸", "ë°•ë¬´"),
            48: ("ğŸŒ«ï¸", "ë°•ë¬´"),
            51: ("ğŸŒ¦ï¸", "ê°€ë²¼ìš´ ì´ìŠ¬ë¹„"),
            61: ("ğŸŒ§ï¸", "ë¹„"),
            71: ("â„ï¸", "ëˆˆ"),
            95: ("â›ˆï¸", "ë‡Œìš°"),
        }
        code = weather["weathercode"]
        emoji, desc = code_map.get(code, ("ğŸŒ¡ï¸", "ì •ë³´ ì—†ìŒ"))

        return f"í…ì‚¬ìŠ¤ ëŒˆëŸ¬ìŠ¤ | {emoji} {desc} | ì™¸ë¶€ì˜¨ë„ : {temp}â„ƒ  |  í’ì† {windspeed}km/h"

    except Exception as e:
        return f"âŒ ì˜ˆì™¸ ë°œìƒ: {str(e)}"